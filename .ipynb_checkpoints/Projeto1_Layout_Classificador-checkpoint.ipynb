{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Ricardo Ribeiro Rodrigues \n",
    "\n",
    "Nome: Guilherme da Franca Silva Escobar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\riywa\\Desktop\\Ciencia_de_dados\\Projeto1-CDados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'WandaVision.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#wandavision o 8 epis√≥dio d√° muito susto kkkkk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@_casthr assim, n√£o t√¥ esperando nada, pq eu d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@_casthr li que o diretor disse que ser√° total...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#@_mbheart foi aqui \\n\\nhttps://t.co/gg4lulxgqf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@_pedrolopss dark e wandavision, at√© pq s√£o as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevancia\n",
       "0  #wandavision o 8 epis√≥dio d√° muito susto kkkkk...           1\n",
       "1  @_casthr assim, n√£o t√¥ esperando nada, pq eu d...           1\n",
       "2  @_casthr li que o diretor disse que ser√° total...           0\n",
       "3    #@_mbheart foi aqui \\n\\nhttps://t.co/gg4lulxgqf           0\n",
       "4  @_pedrolopss dark e wandavision, at√© pq s√£o as...           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"meninos, cuidem dos militares! a mam√£e j√° vai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"wandavision\" √© maravilhosa, gostaria muito de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#wandavision j√° acabouüòîmas amanh√£ tem #thefalc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@_entao_ hahaha siiim! bem atualizado assisti ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@_pedrolopss s√©rio hehehe? as que eu nunca vi ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia\n",
       "0  \"meninos, cuidem dos militares! a mam√£e j√° vai...           0\n",
       "1  \"wandavision\" √© maravilhosa, gostaria muito de...           1\n",
       "2  #wandavision j√° acabouüòîmas amanh√£ tem #thefalc...           1\n",
       "3  @_entao_ hahaha siiim! bem atualizado assisti ...           0\n",
       "4  @_pedrolopss s√©rio hehehe? as que eu nunca vi ...           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "#### Escolhemos como produto a s√©rie de tv WandaVision, uma s√©rie da Marvel com a Disney Plus.  \n",
    "### Sinopse: \n",
    "  Situada tr√™s semanas ap√≥s os eventos de Vingadores: Ultimato (2019), Wanda Maximoff e Vis√£o est√£o vivendo uma vida suburbana id√≠lica na cidade de Westview, no estado de New Jersey, tentando esconder suas verdadeiras identidades. √Ä medida que come√ßam a entrar nas novas d√©cadas, o casal suspeita que as coisas n√£o s√£o o que parecem.(Wikipedia)  \n",
    "### Classifica√ß√£o:  \n",
    "* Classificamos se o tweet se expressa uma opini√£o sobre a s√©rie ou fala de elementos dela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import functools\n",
    "import operator\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[-|><!,-.:#?;\"\"‚Äú‚Äù\\[\\]()\\\\n]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza das mensagens relevantes\n",
    "texto_relevante = ' '.join(train.loc[train.Relevancia == 1, 'Treinamento'])\n",
    "# Limpeza dos caracteres\n",
    "texto_relevante = cleanup(texto_relevante.lower())\n",
    "# Tira links dos tweets\n",
    "texto_relevante = ' '.join(item for item in texto_relevante.split() if not (item.startswith('https//')))\n",
    "# Corrige os espa√ßos dos emojis\n",
    "relevante_split_emoji = emoji.get_emoji_regexp().split(texto_relevante)\n",
    "relevante_split_whitespace = [substr.split() for substr in relevante_split_emoji]\n",
    "relevante_split = functools.reduce(operator.concat, relevante_split_whitespace)\n",
    "texto_relevante = ' '.join(relevante_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wandavision    0.060992\n",
       "de             0.033227\n",
       "que            0.032772\n",
       "a              0.030041\n",
       "e              0.020938\n",
       "                 ...   \n",
       "tao            0.000455\n",
       "cabelo         0.000455\n",
       "seriado        0.000455\n",
       "hipnose        0.000455\n",
       "dia            0.000455\n",
       "Length: 821, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serie relevante e tabela relativa relevante\n",
    "serie_relevante = pd.Series(texto_relevante.split())\n",
    "tabela_relativa_relevante = serie_relevante.value_counts(True)\n",
    "tabela_relativa_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza das mensagens irrelevantes.\n",
    "texto_irrelevante = ' '.join(train.loc[train.Relevancia == 0, 'Treinamento'])\n",
    "# Limpeza dos caracteres\n",
    "texto_irrelevante = cleanup(texto_irrelevante.lower())\n",
    "# Tira links dos tweets\n",
    "texto_irrelevante = ' '.join(item for item in texto_irrelevante.split() if not (item.startswith('https//')))\n",
    "# Corrige os espa√ßos dos emojis\n",
    "irrelevante_split_emoji = emoji.get_emoji_regexp().split(texto_irrelevante)\n",
    "irrelevante_split_whitespace = [substr.split() for substr in irrelevante_split_emoji]\n",
    "irrelevante_split = functools.reduce(operator.concat, irrelevante_split_whitespace)\n",
    "texto_irrelevante = ' '.join(irrelevante_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza dos links\n",
    "Nos decidimos por fazer uma limpeza dos links contidos nos tweets, visto que eles n√£o contribu√≠am para a classifica√ß√£o (est√£o igualmente presentes em relevante e irrelevante) e apenas polu√≠am as bases de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de frequencias das mensagens irrelevantes.\n",
    "serie_irrelevante = pd.Series(texto_irrelevante.split())\n",
    "tabela_relativa_irrelevante = serie_irrelevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wandavision       0.055035\n",
       "de                0.033568\n",
       "que               0.029469\n",
       "e                 0.025176\n",
       "o                 0.024590\n",
       "                    ...   \n",
       "draco             0.000195\n",
       "arrebatador       0.000195\n",
       "merda             0.000195\n",
       "@trypanosoma08    0.000195\n",
       "pegar             0.000195\n",
       "Length: 1638, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazendo o total.\n",
    "todas_mensagens = texto_relevante + texto_irrelevante\n",
    "serie_todas_mensagens = pd.Series(todas_mensagens.split())\n",
    "tabela_relativa_todas_mensagens = serie_todas_mensagens.value_counts(True)\n",
    "tabela_relativa_todas_mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades de irrelevante e relevante\n",
    "ProbR = len(serie_relevante)/len(serie_todas_mensagens)\n",
    "ProbIR = len(serie_irrelevante)/len(serie_todas_mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def classifica_tweet(tweet):\n",
    "    tweet = limpeza(tweet)\n",
    "    prob_tweet_dado_relevante, prob_tweet_dado_irrelevante = 1, 1\n",
    "    for palavra in tweet.split():\n",
    "        if palavra in tabela_relativa_relevante:\n",
    "            prob_tweet_dado_relevante *= (tabela_relativa_relevante[palavra]*len(serie_relevante) + 1)/(len(serie_relevante) + len(tabela_relativa_todas_mensagens))\n",
    "        else:\n",
    "            prob_tweet_dado_relevante *= (1)/(len(serie_relevante) + len(tabela_relativa_todas_mensagens))\n",
    "        if palavra in tabela_relativa_irrelevante:\n",
    "            prob_tweet_dado_irrelevante *= (tabela_relativa_irrelevante[palavra]*len(serie_irrelevante) + 1)/(len(serie_irrelevante) + len(tabela_relativa_todas_mensagens))\n",
    "        else:\n",
    "            prob_tweet_dado_irrelevante *= (1)/(len(serie_irrelevante) + len(tabela_relativa_todas_mensagens))\n",
    "    prob_relevante_dado_tweet = prob_tweet_dado_relevante * ProbR\n",
    "    prob_irrelevante_dado_tweet = prob_tweet_dado_irrelevante * ProbIR\n",
    "    return 1 if prob_relevante_dado_tweet > prob_irrelevante_dado_tweet else 0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza(tweets):\n",
    "    tweets = cleanup(tweets.lower())\n",
    "    tweets = ' '.join(item for item in tweets.split() if not (item.startswith('https//')))\n",
    "    split_emoji = emoji.get_emoji_regexp().split(tweets)\n",
    "    split_whitespace = [substr.split() for substr in split_emoji]\n",
    "    split = functools.reduce(operator.concat, split_whitespace)\n",
    "    tweets = ' '.join(split)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['classificado'] = test['Teste'].apply(classifica_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>classificado</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.12</td>\n",
       "      <td>43.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.33</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>44.50</td>\n",
       "      <td>55.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "classificado      0      1\n",
       "Relevancia                \n",
       "0             56.12  43.88\n",
       "1             33.33  66.67\n",
       "All           44.50  55.50"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Relevancia, test.classificado, margins=True, normalize='index').round(4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>classificado</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.5</td>\n",
       "      <td>21.5</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>44.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "classificado     0     1    All\n",
       "Relevancia                     \n",
       "0             27.5  21.5   49.0\n",
       "1             17.0  34.0   51.0\n",
       "All           44.5  55.5  100.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Relevancia, test.classificado, normalize=True, margins=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativo qualitativo sobre os percentuais obtidos\n",
    "O classificador possui uma maior taxa de acerto nos verdadeiros positivos (66.67 %) do que nos verdadeiros negativos (56.12 %), possui tamb√©m uma maior taxa de acerto total (61.5 %) do que de erro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo\n",
    "Como a probabilidade de ser relevante ou irrelevante √© calculada com base no n√∫mero de apari√ß√µes de cada uma das palavras nos tweets relevantes ou irrelevantes, o sarcasmo ou a dupla nega√ß√£o pode propoiciar uma classifica√ß√£o incorreta, visto que uma palavra que aparece mais vezes nos relevantes pode ser usada num tweet irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plano de expans√£o\n",
    "Para uma futura expans√£o desse projeto, poderiamos englobar outras redes sociais para a coleta de feedback sobre a s√©rie, assim obtendo uma maior quantidade de feedback e sendo mais abrangente nessa coleta, poder√≠amos tamb√©m trazer o classificador para outras s√©ries e filmes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por que n√£o podemos alimentar nossa base de treinamento automaticamente usando o classificador.\n",
    "N√£o podemos alimentar nossa base de treinamento com o pr√≥prio classificador, pois al√©m de ele cometer erros (38.5 %) n√£o haveria um feedback sobre os erros, n√£o sendo poss√≠vel aprimorar o algoritmo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferentes cen√°rios de uso\n",
    "- Classificar e-mails como SPAM ou N√ÉO-SPAM.\n",
    "- Probabilidade de ter uma certa doen√ßa via sequencia gen√©tica.\n",
    "- Prever se um time vai ganhar um jogo levando em conta artigos de an√°lises feitos por especialistas no assunto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sugest√£o de melhorias reais no classificador\n",
    "Uma poss√≠vel melhoria seria a de adicionar mais tweets no banco de dados, para um maior treinamento do classificador, e por consequ√™ncia aumentar a efici√™ncia de nosso classificador, isso poderia ser feito apenas aumentando o n√∫mero de tweets do algoritmo de coleta de tweets e classificando os tweets novos.  \n",
    "Outra melhoria considerada seria a de remover os stopwords visto que elas n√£o adicionam em nada na classifica√ß√£o pois s√£o muito comuns e aparecem igualmentes em ambas as classifica√ß√µes dos tweets, para fazer isso seria o mesmo processo que fizemos na limpeza dos links, que foi basicamente percorrer os tweets com um loop e remover os itens indesejados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
